# infrastructure/terraform.tfvars.example
# Copy this file to terraform.tfvars and fill in your values
# This is a Sample Variables files which is picked up by Terraform to set initial vairables before execution
# Typically the file is called 'terraform.tfvars' and has to be created once we have all information at hand
#
#

# GCP Configuration
project_id      = "your-gcp-project-id"
region          = "us-central1"
environment     = "dev"
billing_account = "ABCDEF-123456-GHIJKL"
org_id          = "123456789012"

# Networking
vpc_name    = "trade-pipeline-vpc"
subnet_name = "trade-pipeline-subnet"
subnet_cidr = "10.0.0.0/24"

allowed_ingress_ranges = ["0.0.0.0/0"]  # Restrict in production
allowed_egress_ranges  = ["0.0.0.0/0"]

# Service Accounts
dataflow_service_account  = "dataflow-sa"
composer_service_account  = "composer-sa"

# Pub/Sub
pubsub_topic_name       = "trades-topic"
pubsub_subscription_name = "trades-dataflow-sub"

# Dataflow
dataflow_job_name     = "trade-processing"
dataflow_template_path = "gs://dataflow-templates/latest/Cloud_PubSub_to_Snowflake"
dataflow_max_workers  = 10

# Composer
composer_name         = "trade-orchestration"
composer_node_count   = 3
composer_machine_type = "n1-standard-2"
composer_disk_size_gb = 100

# Storage Buckets
bucket_names = {
  "data"      = "trade-data"
  "temp"      = "trade-temp"
  "staging"   = "trade-staging"
  "backup"    = "trade-backup"
  "templates" = "trade-templates"
  "state"     = "tf-state"
}

# Snowflake Configuration
snowflake_account  = "your_account"
snowflake_username = "terraform"
snowflake_password = "your_password"

snowflake_database_name = "TRADE_DB"
snowflake_schemas       = ["RAW", "PROCESSED", "ANALYTICS", "AUDIT", "TEST"]
snowflake_data_retention_days = 90

# Snowflake Warehouses
snowflake_warehouses = {
  "load" = {
    size           = "X-SMALL"
    min_cluster_count = 1
    max_cluster_count = 3
    scaling_policy = "STANDARD"
    auto_suspend   = 300
    initially_suspended = true
  }
  "transform" = {
    size           = "SMALL"
    min_cluster_count = 1
    max_cluster_count = 2
    scaling_policy = "ECONOMY"
    auto_suspend   = 300
    initially_suspended = true
  }
  "analytics" = {
    size           = "MEDIUM"
    min_cluster_count = 1
    max_cluster_count = 4
    scaling_policy = "STANDARD"
    auto_suspend   = 300
    initially_suspended = true
  }
}

# Snowflake Users
snowflake_users = {
  "trade_loader" = {
    login_name      = "TRADE_LOADER"
    display_name    = "Trade Data Loader"
    email           = "trade-loader@company.com"
    default_role    = "TRADE_LOADER"
    default_warehouse = "load"
    rsa_public_key  = ""
    must_change_password = false
  }
  "trade_analyst" = {
    login_name      = "TRADE_ANALYST"
    display_name    = "Trade Analyst"
    email           = "trade-analyst@company.com"
    default_role    = "TRADE_ANALYST"
    default_warehouse = "analytics"
    rsa_public_key  = ""
    must_change_password = true
  }
  "trade_admin" = {
    login_name      = "TRADE_ADMIN"
    display_name    = "Trade Admin"
    email           = "trade-admin@company.com"
    default_role    = "TRADE_ADMIN"
    default_warehouse = "transform"
    rsa_public_key  = ""
    must_change_password = false
  }
}

# Snowflake Storage Integration
snowflake_storage_allowed_locations = [
  "gcs://trade-data-*/",
  "gcs://trade-staging-*/",
  "gcs://trade-backup-*/"
]

snowflake_allowed_ip_ranges = ["0.0.0.0/0"]  # Restrict in production

# Monitoring
alert_notification_email = "data-engineering@company.com"
alert_notification_slack = ""  # Optional: Slack webhook URL

# Budget
budget_amount = 1000
budget_alert_thresholds = [50, 75, 90, 100]

# Create state bucket (set to false if bucket already exists)
create_state_bucket = true
